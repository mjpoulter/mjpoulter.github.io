---
layout: post
title:  "Agentic implementation concerns"
date:   2025-10-06
categories: jekyll update
---
The swirl around AI investments continues. AI and AMD tie up announced this morning. But im not going to dwell on that this week. I thought i'd turn to the topic of agents, which is where a lot of the focus seems to be moving, along with attendent hype. We do have the problem that some folks are referring to things as agentic or packaging them as agentic for product reasons, when the capabilities are not really agentic, so more marketecture than architecture in some cases. I think its letting some companies move to usage based pricing models, rather than subscription when they have the potential for long run, unconstrained activities. But some of the things ive seen more resemble batch jobs than agents? But there are of course some real agentic products as well, but not much in the enterprise space as of yet, and enterprises are tending to find it hard to get to grips with managing the risk / reward.

I think we all get the general drift and appeal of agents and agentic flows, and in some sense it doesnt really matter if the agents are AI(LLM) based or more deterministic as many of the same concerns apply before you get to the AI specific probabalistic issues that we have to deal with, that make things a little harder to reason about. Essentially an agent is a process running independently / asynchronously from the main user session. Background or remote processes arent particularly novel, but we seem to be treating them as something new. The basic considerations remain the same, register, locate, authn, authz, security boundaries, execution environments, resource access/visibility , access to services, observability etc. all continue to exist. Do they run locally, remotely, serverless, in kubernetes? orchestrated? isolated etc etc.. All things that need to be managed, much like an api based microservices environment, and so its good to see the linux foundation taking on some opensource approaches to these issues, with projects like agentgateway being contributed by solo.io, the support of mcp and a2a protocols and the possibility of using spiffe for identity and access management. No magic here, just good old fashioned software engineering. 

The place where i tend to think we might be getting things a bit wrong in the implementation is that many approaches are defaulting to deploying in k8s via docker containers, which seems a bit heavy to me for things that might be short lived and lightweight and dont need the industrial strength workload management of k8s, maybe something like cloudflare workers isolates would be more appropriate, or maybe its a mix of deployment environment options that we build around, something local, something lightweight serverless and something more industrial like k8s or istio for long running agents or agent servers. It feels like we are missing an overarching, complete architecture for these use cases as the labs are really all focused on SaaS type offerings and this is not something that has a lot of traction in enterprises yet.

Having said all that, besides all the similarities to existing distributed capabilties implmentations, there is also the aforementioned difference between traditional deterministic flows and the probabalisitic, unpredictable nature of LLM based flows, which of course is a minor difference with major ramifications. I think at the moment the only rational approach, even with agents that have agents checking their work, is to gate all non-reversible activity  with a human in the loop, and thats likely to be the case for some time. The issue there is how do we manage the agentic output so that it allows for quick and easy accept/reject/modify responses from the human orchestrator. Some of it is interface design, much like the coding agents, the interaction model matters, but some of it is a way to filter the output to make it easier to reason about quickly. Some declarative setup for the agents that allows for context to be set and cross checks and validations to be run, so that the final output or recommendations has a better chance of being usable by the human with an overall reduction in cognitive load. I think context is crucial, and that goes to how context engineering is becoming increasingly important, along with the ability of the models and their harnesses to be configurable to the context of each user, team, enterprise etc, such that the tools and the agents can be dropped into an environment and honor the policies, practices, procedures, preferences of the particular enviroment and adapt accordingly. That would all ideally be an industry standard setup like mcp, a2a etc. Without that i think in many situations agents may produce more work for the humans and either drop their productivity or worse lead to more issues because of humans accepting the agentic output because they dont completely understand it and feel under pressure to accept it to move forward quickly. 

This all seems like an area where we are missing important developments in order to be able to really get true value from ai agentic flows. I expect software development will be a place where we will have the opportunity to experiment and learn, but at the moment the vendors are seeing this as a place for differentiation and so its not clear we will get a common approach across the landscape, which will unfortunately make it fragmented and harder to manage and adopt. Its early innings so maybe things will coalesce in the next few months, but im not seeing it at the moment.

{% include comments.html %}
